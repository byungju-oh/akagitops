from fastapi.responses import Response
from fastapi import APIRouter, File, Form, UploadFile, HTTPException
from typing import Optional
import base64
import datetime
from chatbot_service import rag_system
from speech_service import speech_service

# ì±—ë´‡ ë¼ìš°í„° ìƒì„±
chatbot_router = APIRouter(prefix="/chatbot", tags=["chatbot"])

@chatbot_router.post("/ask")
async def chatbot_ask(
    query: str = Form(...),
    image: Optional[UploadFile] = File(None)
):
    """ì±—ë´‡ ì§ˆë¬¸ ì²˜ë¦¬ API"""
    try:
        # ì…ë ¥ ìœ íš¨ì„± ê²€ì‚¬
        if not query or len(query.strip()) < 2:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ì§ˆë¬¸ ê¸¸ì´ ì œí•œ (ë³´ì•ˆìƒ)
        if len(query) > 1000:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 1000ì ì´ë‚´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        image_data = None
        if image:
            # ì´ë¯¸ì§€ íŒŒì¼ í¬ê¸° ì œí•œ (10MB)
            contents = await image.read()
            if len(contents) > 10 * 1024 * 1024:  # 10MB
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. 10MB ì´í•˜ë¡œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            
            # ì´ë¯¸ì§€ í˜•ì‹ í™•ì¸
            if not image.content_type.startswith('image/'):
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            
            image_data = base64.b64encode(contents).decode('utf-8')
        
        # ìŠ¤ë§ˆíŠ¸ RAG ì‹œìŠ¤í…œìœ¼ë¡œ ë‹µë³€ ìƒì„±
        answer, source = rag_system.smart_answer(query.strip(), image_data)
        
        return {
            "success": True,
            "answer": answer,
            "source": source,
            "query": query.strip(),
            "has_image": image is not None,
            "timestamp": "2024-12-19"  # ì‹¤ì œë¡œëŠ” datetime.now() ì‚¬ìš©
        }
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
        
    except Exception as e:
        print(f"ì±—ë´‡ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "answer": """ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. 

ë‹¤ìŒê³¼ ê°™ì´ ì‹œë„í•´ë³´ì„¸ìš”:
â€¢ ì ì‹œ í›„ ë‹¤ì‹œ ì§ˆë¬¸í•´ë³´ì„¸ìš”
â€¢ ì§ˆë¬¸ì„ ë” ê°„ë‹¨í•˜ê²Œ ë°”ê¿”ë³´ì„¸ìš”
â€¢ ê¸´ê¸‰í•œ ê²½ìš° 119 ë˜ëŠ” 120ìœ¼ë¡œ ì—°ë½í•˜ì„¸ìš”

ì„œë¹„ìŠ¤ ì´ìš©ì— ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤.""",
            "source": "ì˜¤ë¥˜"
        }

@chatbot_router.get("/health")
async def chatbot_health():
    """ì±—ë´‡ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "message": "ì±—ë´‡ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
        "features": {
            "text_chat": True,
            "image_upload": True,
            "rag_system": True,
            "fallback_llm": True
        },
        "supported_queries": [
            "ì‹±í¬í™€ ì‹ ê³  ë°©ë²•",
            "ì‹±í¬í™€ í¬ê¸° ì¸¡ì •",
            "ë°œìƒ ì›ì¸ ë° ì˜ˆë°©",
            "í”¼í•´ ë³´ìƒ ì ˆì°¨",
            "ì„œë¹„ìŠ¤ ì´ìš© ë°©ë²•"
        ]
    }

@chatbot_router.get("/examples")
async def get_example_questions():
    """ì˜ˆì‹œ ì§ˆë¬¸ ëª©ë¡ ì œê³µ"""
    return {
        "categories": {
            "ì‹ ê³ _ì ‘ìˆ˜": [
                "ì‹±í¬í™€ì„ ë°œê²¬í–ˆëŠ”ë° ì–´ë””ì— ì‹ ê³ í•´ì•¼ í•˜ë‚˜ìš”?",
                "ì‹±í¬í™€ ì‹ ê³ í•  ë•Œ ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•œê°€ìš”?",
                "ì‘ê¸‰ìƒí™©ì¼ ë•Œ ì—°ë½ì²˜ëŠ” ì–´ë””ì¸ê°€ìš”?"
            ],
            "ì¸¡ì •_í‰ê°€": [
                "ì‹±í¬í™€ í¬ê¸°ëŠ” ì–´ë–»ê²Œ ì¸¡ì •í•˜ë‚˜ìš”?",
                "ì–´ëŠ ì •ë„ í¬ê¸°ë¶€í„° ìœ„í—˜í•œê°€ìš”?",
                "ê¹Šì´ë¥¼ ì•Œ ìˆ˜ ì—†ì„ ë•ŒëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
            ],
            "ì›ì¸_ì˜ˆë°©": [
                "ì‹±í¬í™€ì´ ìƒê¸°ëŠ” ì›ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì‹±í¬í™€ì„ ë¯¸ë¦¬ ì˜ˆë°©í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?",
                "ì–´ë–¤ ì§•í›„ë¥¼ ë´ì•¼ í•˜ë‚˜ìš”?"
            ],
            "ë³´ìƒ_ì ˆì°¨": [
                "ì‹±í¬í™€ í”¼í•´ ë³´ìƒì€ ì–´ë–»ê²Œ ë°›ë‚˜ìš”?",
                "ë³´ìƒ ì‹ ì²­ì— í•„ìš”í•œ ì„œë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "ë³´ìƒ ì²˜ë¦¬ ê¸°ê°„ì€ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?"
            ],
            "ì„œë¹„ìŠ¤_ì´ìš©": [
                "ì´ ì„œë¹„ìŠ¤ëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?",
                "ìœ„í—˜ì§€ë„ëŠ” ì–´ë””ì„œ ë³¼ ìˆ˜ ìˆë‚˜ìš”?",
                "ì•ˆì „ ê²½ë¡œ ê²€ìƒ‰ ê¸°ëŠ¥ì€ ì–´ë–»ê²Œ ì“°ë‚˜ìš”?"
            ]
        }
    }



# ê¸°ì¡´ ë¼ìš°í„°ì— ìŒì„± ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
@chatbot_router.post("/ask-with-voice")
async def chatbot_ask_with_voice(
    query: str = Form(...),
    image: Optional[UploadFile] = File(None),
    voice_name: str = Form("ko-KR-HyunsuMultilingualNeural")
):
    """ì±—ë´‡ ì§ˆë¬¸ + TTS ìŒì„± ì‘ë‹µ API"""
    try:
        # ê¸°ì¡´ ì±—ë´‡ ë¡œì§ê³¼ ë™ì¼
        if not query or len(query.strip()) < 2:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if len(query) > 1000:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 1000ì ì´ë‚´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        image_data = None
        if image:
            contents = await image.read()
            if len(contents) > 10 * 1024 * 1024:  # 10MB
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")
            
            if not image.content_type.startswith('image/'):
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            
            image_data = base64.b64encode(contents).decode('utf-8')
        
        # RAG ì‹œìŠ¤í…œìœ¼ë¡œ ë‹µë³€ ìƒì„±
        answer, source = rag_system.smart_answer(query.strip(), image_data)
        
        # TTSë¡œ ìŒì„± ìƒì„±
        try:
            audio_data = speech_service.text_to_speech(answer, voice_name)
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        except Exception as tts_error:
            print(f"TTS ì˜¤ë¥˜: {tts_error}")
            audio_base64 = None
        
        return {
            "success": True,
            "answer": answer,
            "source": source,
            "query": query.strip(),
            "has_image": image is not None,
            "audio_data": audio_base64,  # Base64 ì¸ì½”ë”©ëœ ìŒì„± ë°ì´í„°
            "voice_name": voice_name,
            "timestamp": "2024-12-19"
        }
        
    except HTTPException:
        raise
        
    except Exception as e:
        print(f"ì±—ë´‡ ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "source": "ì˜¤ë¥˜",
            "audio_data": None
        }

@chatbot_router.post("/text-to-speech")
async def text_to_speech_endpoint(
    text: str = Form(...),
    voice_name: str = Form("ko-KR-HyunsuMultilingualNeural"),
    return_audio: bool = Form(False)  # Trueë©´ ì§ì ‘ ì˜¤ë””ì˜¤ ë°˜í™˜, Falseë©´ Base64
):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë…ë¦½ API"""
    try:
        if not text or len(text.strip()) < 1:
            raise HTTPException(status_code=400, detail="ë³€í™˜í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if len(text) > 2000:
            raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 2000ì ì´ë‚´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # TTS ì‹¤í–‰
        audio_data = speech_service.text_to_speech(text.strip(), voice_name)
        
        if return_audio:
            # ì§ì ‘ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ë°˜í™˜ (ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ì¬ìƒ ê°€ëŠ¥)
            return Response(
                content=audio_data,
                media_type="audio/wav",
                headers={
                    "Content-Disposition": "attachment; filename=speech.wav",
                    "Content-Length": str(len(audio_data))
                }
            )
        else:
            # Base64ë¡œ ì¸ì½”ë”©í•´ì„œ JSONìœ¼ë¡œ ë°˜í™˜
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            return {
                "success": True,
                "text": text.strip(),
                "voice_name": voice_name,
                "audio_data": audio_base64,
                "audio_size": len(audio_data)
            }
        
    except HTTPException:
        raise
        
    except Exception as e:
        print(f"TTS API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ìŒì„± í•©ì„± ì˜¤ë¥˜: {str(e)}")

@chatbot_router.post("/voice-to-text")
async def voice_to_text_endpoint(
    audio: UploadFile = File(...)
):
    """ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” STT API"""
    try:
        if not audio.content_type.startswith('audio/'):
            raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        audio_data = await audio.read()
        if len(audio_data) > 25 * 1024 * 1024:  # 25MB
            raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. 25MB ì´í•˜ë¡œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        # STT ì‹¤í–‰
        recognized_text = speech_service.speech_to_text(audio_data)
        
        return {
            "success": True,
            "recognized_text": recognized_text,
            "audio_filename": audio.filename,
            "audio_size": len(audio_data),
            "timestamp": datetime.datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
        
    except Exception as e:
        print(f"STT API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}")

@chatbot_router.post("/voice-chat")
async def voice_chat_endpoint(
    audio: UploadFile = File(...),
    voice_name: str = Form("ko-KR-HyunsuMultilingualNeural"),
    image: Optional[UploadFile] = File(None)
):
    """ì™„ì „í•œ ìŒì„± ëŒ€í™”: STT â†’ LLM â†’ TTS"""
    try:
        # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦
        if not audio.content_type.startswith('audio/'):
            raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        audio_data = await audio.read()
        if len(audio_data) > 25 * 1024 * 1024:  # 25MB
            raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")
        
        # 2. ì´ë¯¸ì§€ ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
        image_data = None
        if image:
            image_contents = await image.read()
            if len(image_contents) > 10 * 1024 * 1024:  # 10MB
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")
            
            if not image.content_type.startswith('image/'):
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            
            image_data = base64.b64encode(image_contents).decode('utf-8')
        
        # 3. STT: ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        try:
            recognized_text = speech_service.speech_to_text(audio_data)
            print(f"ğŸ¤ STT ê²°ê³¼: {recognized_text}")
        except Exception as stt_error:
            print(f"âŒ STT ì˜¤ë¥˜: {stt_error}")
            raise HTTPException(status_code=400, detail=f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(stt_error)}")
        
        if not recognized_text or len(recognized_text.strip()) < 2:
            raise HTTPException(status_code=400, detail="ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # 4. LLM: RAG ì‹œìŠ¤í…œìœ¼ë¡œ ë‹µë³€ ìƒì„±
        try:
            answer, source = rag_system.smart_answer(recognized_text.strip(), image_data)
            print(f"ğŸ¤– LLM ì‘ë‹µ: {answer[:100]}...")
        except Exception as llm_error:
            print(f"âŒ LLM ì˜¤ë¥˜: {llm_error}")
            answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            source = "ì˜¤ë¥˜"
        
        # 5. TTS: ë‹µë³€ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        try:
            audio_response = speech_service.text_to_speech(answer, voice_name)
            audio_base64 = base64.b64encode(audio_response).decode('utf-8')
            print(f"ğŸ”Š TTS ì„±ê³µ: {len(audio_response)} bytes")
        except Exception as tts_error:
            print(f"âŒ TTS ì˜¤ë¥˜: {tts_error}")
            audio_base64 = None
        
        return {
            "success": True,
            "recognized_text": recognized_text,
            "answer": answer,
            "source": source,
            "audio_data": audio_base64,
            "voice_name": voice_name,
            "has_image": image is not None,
            "processing_time": "ì™„ë£Œ",
            "timestamp": datetime.datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
        
    except Exception as e:
        print(f"ìŒì„± ëŒ€í™” API ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": "ìŒì„± ëŒ€í™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "recognized_text": "",
            "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "source": "ì˜¤ë¥˜",
            "audio_data": None
        }

@chatbot_router.post("/voice-test")
async def voice_test_endpoint():
    """ìŒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ API"""
    try:
        # TTS í…ŒìŠ¤íŠ¸
        test_text = "ì•ˆë…•í•˜ì„¸ìš”. ì‹±í¬í™€ ìŒì„± ì–´ì‹œìŠ¤í„´íŠ¸ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."
        audio_data = speech_service.text_to_speech(test_text)
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        
        return {
            "success": True,
            "message": "ìŒì„± ì„œë¹„ìŠ¤ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.",
            "test_text": test_text,
            "audio_data": audio_base64,
            "audio_size": len(audio_data),
            "service_status": {
                "speech_enabled": speech_service.enabled,
                "tts_available": True,
                "stt_available": True
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"ìŒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}",
            "service_status": {
                "speech_enabled": speech_service.enabled,
                "tts_available": False,
                "stt_available": False
            }
        }

@chatbot_router.get("/speech/voices")
async def get_available_voices():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ë°˜í™˜"""
    return {
        "korean_voices": [
            {
                "name": "ko-KR-HyunsuMultilingualNeural",
                "display_name": "í˜„ìˆ˜ (ë‚¨ì„±, ë‹¤êµ­ì–´)",
                "gender": "Male",
                "recommended": True
            },
            {
                "name": "ko-KR-JiminNeural",
                "display_name": "ì§€ë¯¼ (ì—¬ì„±)",
                "gender": "Female",
                "recommended": True
            },
            {
                "name": "ko-KR-BongJinNeural", 
                "display_name": "ë´‰ì§„ (ë‚¨ì„±)",
                "gender": "Male",
                "recommended": False
            },
            {
                "name": "ko-KR-SunHiNeural",
                "display_name": "ì„ í¬ (ì—¬ì„±)",
                "gender": "Female", 
                "recommended": False
            }
        ],
        "default_voice": "ko-KR-HyunsuMultilingualNeural",
        "note": "í˜„ìˆ˜ ë‹¤êµ­ì–´ ìŒì„±ì´ ê°€ì¥ ìì—°ìŠ¤ëŸ½ê³  ì‹±í¬í™€ ê´€ë ¨ ì „ë¬¸ ìš©ì–´ ë°œìŒì— ì í•©í•©ë‹ˆë‹¤."
    }