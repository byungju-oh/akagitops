# backend/chatbot_routes.py - ì‹±í¬í™€ ë¶„ì„ ê¸°ëŠ¥ í¬í•¨
from fastapi.responses import Response
from fastapi import APIRouter, File, Form, UploadFile, HTTPException
from typing import Optional
import base64
import datetime
from chatbot_service import rag_system
from speech_service import speech_service
from sinkhole_analysis_service import sinkhole_analyzer

# ì±—ë´‡ ë¼ìš°í„° ìƒì„±
chatbot_router = APIRouter(prefix="/chatbot", tags=["chatbot"])

@chatbot_router.post("/ask")
async def chatbot_ask(
    query: str = Form(...),
    image: Optional[UploadFile] = File(None)
):
    """ì±—ë´‡ ì§ˆë¬¸ ì²˜ë¦¬ API - ì‹±í¬í™€ ë¶„ì„ ê¸°ëŠ¥ í¬í•¨"""
    try:
        # ì…ë ¥ ìœ íš¨ì„± ê²€ì‚¬
        if not query or len(query.strip()) < 2:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ì§ˆë¬¸ ê¸¸ì´ ì œí•œ (ë³´ì•ˆìƒ)
        if len(query) > 1000:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 1000ì ì´ë‚´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        image_data = None
        image_analysis_result = None
        
        if image:
            # ì´ë¯¸ì§€ íŒŒì¼ í¬ê¸° ì œí•œ (10MB)
            contents = await image.read()
            if len(contents) > 10 * 1024 * 1024:  # 10MB
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. 10MB ì´í•˜ë¡œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            
            # ì´ë¯¸ì§€ í˜•ì‹ í™•ì¸
            if not image.content_type.startswith('image/'):
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            
            image_data = base64.b64encode(contents).decode('utf-8')
            
            # ì´ë¯¸ì§€ ë¶„ì„ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ (ì„ íƒì‚¬í•­)
            if sinkhole_analyzer.is_available:
                try:
                    is_sinkhole, confidence, analysis_result = sinkhole_analyzer.analyze_image(image_data)
                    image_analysis_result = {
                        "is_sinkhole": is_sinkhole,
                        "confidence": confidence,
                        "confidence_percent": confidence * 100,
                        "total_detections": analysis_result.get("total_detections", 0)
                    }
                    print(f"ğŸ“Š ì´ë¯¸ì§€ ë¶„ì„ ë©”íƒ€ë°ì´í„°: {image_analysis_result}")
                except Exception as e:
                    print(f"âš ï¸ ì´ë¯¸ì§€ ë¶„ì„ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # Enhanced RAG ì‹œìŠ¤í…œìœ¼ë¡œ ë‹µë³€ ìƒì„± (ì´ë¯¸ì§€ ë¶„ì„ í¬í•¨)
        answer, source = rag_system.smart_answer(query.strip(), image_data)
        
        response_data = {
            "success": True,
            "answer": answer,
            "source": source,
            "query": query.strip(),
            "has_image": image is not None,
            "timestamp": datetime.datetime.now().isoformat()
        }
        
        # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if image_analysis_result:
            response_data["image_analysis"] = image_analysis_result
        
        return response_data
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
        
    except Exception as e:
        print(f"ì±—ë´‡ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "answer": """ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. 

ë‹¤ìŒê³¼ ê°™ì´ ì‹œë„í•´ë³´ì„¸ìš”:
â€¢ ì ì‹œ í›„ ë‹¤ì‹œ ì§ˆë¬¸í•´ë³´ì„¸ìš”
â€¢ ì§ˆë¬¸ì„ ë” ê°„ë‹¨í•˜ê²Œ ë°”ê¿”ë³´ì„¸ìš”
â€¢ ê¸´ê¸‰í•œ ê²½ìš° 119 ë˜ëŠ” 120ìœ¼ë¡œ ì—°ë½í•˜ì„¸ìš”

ì„œë¹„ìŠ¤ ì´ìš©ì— ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤.""",
            "source": "ì˜¤ë¥˜",
            "timestamp": datetime.datetime.now().isoformat()
        }

@chatbot_router.post("/analyze-image")
async def analyze_image_only(
    image: UploadFile = File(...)
):
    """ì´ë¯¸ì§€ë§Œ ë¶„ì„í•˜ëŠ” ì „ìš© API"""
    try:
        # ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦
        if not image.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        contents = await image.read()
        if len(contents) > 10 * 1024 * 1024:  # 10MB
            raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")
        
        # Azure Custom Vision ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if not sinkhole_analyzer.is_available:
            raise HTTPException(
                status_code=503, 
                detail="ì´ë¯¸ì§€ ë¶„ì„ ì„œë¹„ìŠ¤ë¥¼ í˜„ì¬ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        # ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰
        image_data = base64.b64encode(contents).decode('utf-8')
        is_sinkhole, confidence, analysis_result = sinkhole_analyzer.analyze_image(image_data)
        
        # ì£¼ì„ ì´ë¯¸ì§€ ìƒì„± (ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨)
        annotated_image = None
        if analysis_result.get("predictions"):
            annotated_image = sinkhole_analyzer.create_annotated_image(image_data, analysis_result)
        
        # ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ ê¶Œì¥ì‚¬í•­ ìƒì„±
        if is_sinkhole and confidence >= 0.7:
            recommendation = "ì¦‰ì‹œ ì•ˆì „ ì¡°ì¹˜ë¥¼ ì·¨í•˜ê³  119ì— ì‹ ê³ í•˜ì„¸ìš”."
            risk_level = "high"
        elif confidence >= 0.5:
            recommendation = "ì „ë¬¸ê°€ í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            risk_level = "medium"
        else:
            recommendation = "ì‹±í¬í™€ë¡œ ë³´ì´ì§€ ì•Šì§€ë§Œ ì˜ì‹¬ìŠ¤ëŸ¬ìš°ë©´ ì‹ ê³ í•˜ì„¸ìš”."
            risk_level = "low"
        
        return {
            "success": True,
            "analysis_result": {
                "is_sinkhole": is_sinkhole,
                "confidence": confidence,
                "confidence_percent": round(confidence * 100, 1),
                "risk_level": risk_level,
                "recommendation": recommendation,
                "predictions": analysis_result.get("predictions", []),
                "total_detections": analysis_result.get("total_detections", 0),
                "image_dimensions": analysis_result.get("image_dimensions", {}),
                "annotated_image": annotated_image  # Base64 ì£¼ì„ ì´ë¯¸ì§€
            },
            "timestamp": datetime.datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
        
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "timestamp": datetime.datetime.now().isoformat()
        }

@chatbot_router.get("/health")
async def chatbot_health():
    """ì±—ë´‡ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ - ì‹±í¬í™€ ë¶„ì„ ê¸°ëŠ¥ í¬í•¨"""
    return {
        "status": "healthy",
        "message": "ì±—ë´‡ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
        "features": {
            "text_chat": True,
            "image_upload": True,
            "rag_system": True,
            "fallback_llm": True,
            "sinkhole_analysis": sinkhole_analyzer.is_available,  # ìƒˆ ê¸°ëŠ¥
            "voice_support": True
        },
        "services": {
            "azure_openai": rag_system.client is not None,
            "azure_custom_vision": sinkhole_analyzer.is_available,
            "azure_speech": True  # speech_service ê°€ì •
        },
        "supported_queries": [
            "ì‹±í¬í™€ ì‹ ê³  ë°©ë²•",
            "ì‹±í¬í™€ í¬ê¸° ì¸¡ì •", 
            "ë°œìƒ ì›ì¸ ë° ì˜ˆë°©",
            "í”¼í•´ ë³´ìƒ ì ˆì°¨",
            "ì„œë¹„ìŠ¤ ì´ìš© ë°©ë²•",
            "ì‚¬ì§„ ë¶„ì„ì„ í†µí•œ ì‹±í¬í™€ íƒì§€"  # ìƒˆ ê¸°ëŠ¥
        ]
    }

@chatbot_router.get("/examples")
async def get_example_questions():
    """ì˜ˆì‹œ ì§ˆë¬¸ ëª©ë¡ ì œê³µ - ì‚¬ì§„ ë¶„ì„ ì˜ˆì‹œ ì¶”ê°€"""
    return {
        "categories": {
            "ì‹ ê³ _ì ‘ìˆ˜": [
                "ì‹±í¬í™€ì„ ë°œê²¬í–ˆëŠ”ë° ì–´ë””ì— ì‹ ê³ í•´ì•¼ í•˜ë‚˜ìš”?",
                "ì‹±í¬í™€ ì‹ ê³ í•  ë•Œ ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•œê°€ìš”?",
                "ì‘ê¸‰ìƒí™©ì¼ ë•Œ ì—°ë½ì²˜ëŠ” ì–´ë””ì¸ê°€ìš”?"
            ],
            "ì¸¡ì •_í‰ê°€": [
                "ì‹±í¬í™€ í¬ê¸°ëŠ” ì–´ë–»ê²Œ ì¸¡ì •í•˜ë‚˜ìš”?",
                "ì–´ëŠ ì •ë„ í¬ê¸°ë¶€í„° ìœ„í—˜í•œê°€ìš”?",
                "ê¹Šì´ë¥¼ ì•Œ ìˆ˜ ì—†ì„ ë•ŒëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
            ],
            "ì‚¬ì§„_ë¶„ì„": [  # ìƒˆ ì¹´í…Œê³ ë¦¬
                "ì´ ì‚¬ì§„ì´ ì‹±í¬í™€ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”",
                "ì‚¬ì§„ìœ¼ë¡œ ì‹±í¬í™€ì„ ë¶„ì„í•  ìˆ˜ ìˆë‚˜ìš”?",
                "AI ë¶„ì„ ì •í™•ë„ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?"
            ],
            "ì›ì¸_ì˜ˆë°©": [
                "ì‹±í¬í™€ì´ ìƒê¸°ëŠ” ì›ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì‹±í¬í™€ì„ ë¯¸ë¦¬ ì˜ˆë°©í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ìˆë‚˜ìš”?",
                "ì–´ë–¤ ì§•í›„ë¥¼ ë´ì•¼ í•˜ë‚˜ìš”?"
            ],
            "ë³´ìƒ_ì ˆì°¨": [
                "ì‹±í¬í™€ í”¼í•´ ë³´ìƒì€ ì–´ë–»ê²Œ ë°›ë‚˜ìš”?",
                "ë³´ìƒ ì‹ ì²­ì— í•„ìš”í•œ ì„œë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "ë³´ìƒ ì²˜ë¦¬ ê¸°ê°„ì€ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?"
            ],
            "ì„œë¹„ìŠ¤_ì´ìš©": [
                "ì´ ì„œë¹„ìŠ¤ëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?",
                "ìœ„í—˜ì§€ë„ëŠ” ì–´ë””ì„œ ë³¼ ìˆ˜ ìˆë‚˜ìš”?",
                "ì•ˆì „ ê²½ë¡œ ê²€ìƒ‰ ê¸°ëŠ¥ì€ ì–´ë–»ê²Œ ì“°ë‚˜ìš”?"
            ]
        },
        "image_upload_tips": [
            "ì„ ëª…í•˜ê³  ë°ì€ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            "ê°€ëŠ¥í•˜ë©´ ì—¬ëŸ¬ ê°ë„ì—ì„œ ì´¬ì˜í•˜ì„¸ìš”", 
            "ì•ˆì „ê±°ë¦¬ë¥¼ ìœ ì§€í•˜ë©° ì´¬ì˜í•˜ì„¸ìš”",
            "10MB ì´í•˜ì˜ jpg, png íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
        ]
    }

# ê¸°ì¡´ ìŒì„± ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸ë“¤ë„ ìœ ì§€
@chatbot_router.post("/ask-with-voice")
async def chatbot_ask_with_voice(
    query: str = Form(...),
    image: Optional[UploadFile] = File(None),
    voice_name: str = Form("ko-KR-HyunsuMultilingualNeural")
):
    """ì±—ë´‡ ì§ˆë¬¸ + TTS ìŒì„± ì‘ë‹µ API - ì‹±í¬í™€ ë¶„ì„ í¬í•¨"""
    try:
        # ê¸°ì¡´ ì±—ë´‡ ë¡œì§ê³¼ ë™ì¼
        if not query or len(query.strip()) < 2:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if len(query) > 1000:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 1000ì ì´ë‚´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        image_data = None
        if image:
            contents = await image.read()
            if len(contents) > 10 * 1024 * 1024:  # 10MB
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")
            
            if not image.content_type.startswith('image/'):
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            
            image_data = base64.b64encode(contents).decode('utf-8')
        
        # Enhanced RAG ì‹œìŠ¤í…œìœ¼ë¡œ ë‹µë³€ ìƒì„± (ì´ë¯¸ì§€ ë¶„ì„ í¬í•¨)
        answer, source = rag_system.smart_answer(query.strip(), image_data)
        
        # TTSë¡œ ìŒì„± ìƒì„±
        try:
            audio_data = speech_service.text_to_speech(answer, voice_name)
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        except Exception as tts_error:
            print(f"TTS ì˜¤ë¥˜: {tts_error}")
            audio_base64 = None
        
        return {
            "success": True,
            "answer": answer,
            "source": source,
            "query": query.strip(),
            "has_image": image is not None,
            "audio_data": audio_base64,  # Base64 ì¸ì½”ë”©ëœ ìŒì„± ë°ì´í„°
            "voice_name": voice_name,
            "timestamp": datetime.datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
        
    except Exception as e:
        print(f"ì±—ë´‡ ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "source": "ì˜¤ë¥˜",
            "audio_data": None,
            "timestamp": datetime.datetime.now().isoformat()
        }

@chatbot_router.post("/voice-conversation")
async def voice_conversation(
    audio: UploadFile = File(...),
    image: Optional[UploadFile] = File(None),
    voice_name: str = Form("ko-KR-HyunsuMultilingualNeural")
):
    """ìŒì„± ëŒ€í™” API - STT + ì‹±í¬í™€ ë¶„ì„ + LLM + TTS"""
    try:
        # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦
        if not audio.content_type.startswith('audio/'):
            raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        audio_data = await audio.read()
        if len(audio_data) > 25 * 1024 * 1024:  # 25MB
            raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")
        
        # 2. ì´ë¯¸ì§€ ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
        image_data = None
        if image:
            image_contents = await image.read()
            if len(image_contents) > 10 * 1024 * 1024:  # 10MB
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")
            
            if not image.content_type.startswith('image/'):
                raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            
            image_data = base64.b64encode(image_contents).decode('utf-8')
        
        # 3. STT: ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        try:
            recognized_text = speech_service.speech_to_text(audio_data)
            print(f"ğŸ¤ STT ê²°ê³¼: {recognized_text}")
        except Exception as stt_error:
            print(f"âŒ STT ì˜¤ë¥˜: {stt_error}")
            raise HTTPException(status_code=400, detail=f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(stt_error)}")
        
        if not recognized_text or len(recognized_text.strip()) < 2:
            raise HTTPException(status_code=400, detail="ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # 4. Enhanced RAG: í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ë¶„ì„
        try:
            answer, source = rag_system.smart_answer(recognized_text.strip(), image_data)
            print(f"ğŸ¤– LLM ì‘ë‹µ: {answer[:100]}...")
        except Exception as llm_error:
            print(f"âŒ LLM ì˜¤ë¥˜: {llm_error}")
            answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            source = "ì˜¤ë¥˜"
        
        # 5. TTS: ë‹µë³€ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        try:
            audio_response = speech_service.text_to_speech(answer, voice_name)
            audio_base64 = base64.b64encode(audio_response).decode('utf-8')
            print(f"ğŸ”Š TTS ì„±ê³µ: {len(audio_response)} bytes")
        except Exception as tts_error:
            print(f"âŒ TTS ì˜¤ë¥˜: {tts_error}")
            audio_base64 = None
        
        return {
            "success": True,
            "recognized_text": recognized_text,
            "answer": answer,
            "source": source,
            "audio_data": audio_base64,
            "voice_name": voice_name,
            "has_image": image is not None,
            "processing_time": "ì™„ë£Œ",
            "timestamp": datetime.datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
        
    except Exception as e:
        print(f"ìŒì„± ëŒ€í™” API ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": "ìŒì„± ëŒ€í™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "recognized_text": "",
            "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "source": "ì˜¤ë¥˜",
            "audio_data": None,
            "timestamp": datetime.datetime.now().isoformat()
        }

@chatbot_router.post("/voice-test")
async def voice_test_endpoint():
    """ìŒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ API"""
    try:
        # TTS í…ŒìŠ¤íŠ¸
        test_text = "ì•ˆë…•í•˜ì„¸ìš”. ì‹±í¬í™€ ì‹ ê³  ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ìŒì„± ì„œë¹„ìŠ¤ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤."
        audio_data = speech_service.text_to_speech(test_text)
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        
        return {
            "success": True,
            "message": "ìŒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì„±ê³µ",
            "test_text": test_text,
            "audio_data": audio_base64,
            "timestamp": datetime.datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"ìŒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}",
            "timestamp": datetime.datetime.now().isoformat()
        }

@chatbot_router.get("/analysis-stats")
async def get_analysis_statistics():
    """ì‹±í¬í™€ ë¶„ì„ í†µê³„ ì •ë³´ ì œê³µ (ì„ íƒì‚¬í•­)"""
    return {
        "sinkhole_analysis": {
            "service_available": sinkhole_analyzer.is_available,
            "supported_formats": ["jpg", "jpeg", "png", "bmp"],
            "max_file_size_mb": 10,
            "confidence_threshold": 0.7,
            "detection_accuracy": "ì•½ 85-90% (í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ì¤€)",
            "processing_time": "ì¼ë°˜ì ìœ¼ë¡œ 2-5ì´ˆ"
        },
        "usage_tips": [
            "ë°ê³  ì„ ëª…í•œ ì‚¬ì§„ì„ ì‚¬ìš©í•˜ì„¸ìš”",
            "ì‹±í¬í™€ ì „ì²´ê°€ ë³´ì´ë„ë¡ ì´¬ì˜í•˜ì„¸ìš”",
            "ì•ˆì „ê±°ë¦¬ë¥¼ ìœ ì§€í•˜ë©° ì´¬ì˜í•˜ì„¸ìš”",
            "AI ë¶„ì„ì€ ì°¸ê³ ìš©ì´ë©° ì „ë¬¸ê°€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"
        ],
        "disclaimer": "AI ë¶„ì„ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ í˜„ì¥ í™•ì¸ê³¼ ì „ë¬¸ê°€ íŒë‹¨ì´ í•„ìš”í•©ë‹ˆë‹¤."
    }