import React, { useState, useEffect, useRef } from 'react';

const VoiceAssistantWidget = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [showResponse, setShowResponse] = useState(false);
  const [responseData, setResponseData] = useState({ question: '', answer: '', source: '' });
  const [showOverlay, setShowOverlay] = useState(false);
  const [statusText, setStatusText] = useState('');
  const [statusIcon, setStatusIcon] = useState('ğŸ¤');
  const [recordedAudio, setRecordedAudio] = useState(null);
  const [mediaRecorder, setMediaRecorder] = useState(null);
  const [useBackendSTT, setUseBackendSTT] = useState(false); // STT ë°©ì‹ ì„ íƒ

  const recognitionRef = useRef(null);
  const speechSynthesisRef = useRef(window.speechSynthesis);
  const audioChunksRef = useRef([]);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
  useEffect(() => {
    initSpeechRecognition();
    //initMediaRecorder();
    
    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
      speechSynthesisRef.current.cancel();
      if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
    }
    };
  }, []);

  // MediaRecorder ì´ˆê¸°í™” (ë°±ì—”ë“œ STTìš©)
  // const initMediaRecorder = async () => {
  //   try {
  //     const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  //     const recorder = new MediaRecorder(stream);
      
  //     recorder.ondataavailable = (event) => {
  //       if (event.data.size > 0) {
  //         audioChunksRef.current.push(event.data);
  //       }
  //     };
      
  //     recorder.onstop = () => {
  //       const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
  //       setRecordedAudio(audioBlob);
  //       audioChunksRef.current = [];
        
  //       // ë°±ì—”ë“œ STT ì‚¬ìš© ì‹œ ìë™ìœ¼ë¡œ ì²˜ë¦¬
  //       if (useBackendSTT) {
  //         processBackendSTT(audioBlob);
  //       }
  //     };
      
  //     setMediaRecorder(recorder);
  //     console.log('âœ… MediaRecorder ì´ˆê¸°í™” ì™„ë£Œ');
  //   } catch (error) {
  //     console.error('âŒ MediaRecorder ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
  //   }
  // };

  // ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
  const initSpeechRecognition = () => {
    if ('webkitSpeechRecognition' in window) {
      recognitionRef.current = new window.webkitSpeechRecognition();
    } else if ('SpeechRecognition' in window) {
      recognitionRef.current = new window.SpeechRecognition();
    } else {
      console.error('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return false;
    }

    const recognition = recognitionRef.current;
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = 'ko-KR';

    recognition.onstart = () => {
      console.log('ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘');
      updateStatus('recording', 'ğŸ”´', 'ìŒì„± ì¸ì‹ ì¤‘...', 'ì§€ê¸ˆ ë§ì”€í•´ì£¼ì„¸ìš”');
    };

    recognition.onresult = (event) => {
      const transcript = event.results[0][0].transcript;
      console.log('âœ… ì¸ì‹ëœ í…ìŠ¤íŠ¸:', transcript);
      hideOverlay();
      processVoiceQuery(transcript);
    };

    recognition.onerror = (event) => {
      console.error('âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error);
      hideOverlay();
      resetButton();
      
      let errorMessage = 'ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      if (event.error === 'no-speech') {
        errorMessage = 'ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
      } else if (event.error === 'network') {
        errorMessage = 'ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      }
      
      displayResponse('ì˜¤ë¥˜', errorMessage, 'ì˜¤ë¥˜');
    };

    recognition.onend = () => {
      console.log('ğŸ”š ìŒì„± ì¸ì‹ ì¢…ë£Œ');
      setIsRecording(false);
      if (!isProcessing) {
        hideOverlay();
        resetButton();
      }
    };

    return true;
  };

  // ë°±ì—”ë“œ STT ì²˜ë¦¬
  const processBackendSTT = async (audioBlob) => {
    setIsProcessing(true);
    updateStatus('processing', 'ğŸ¯', 'ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...', 'ë°±ì—”ë“œ STT ì²˜ë¦¬ ì¤‘');
    
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.wav');
      const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';
      const response = await fetch('http://${API_BASE_URL}/chatbot/voice-to-text', {
        method: 'POST',
        body: formData
      });
      
      if (!response.ok) {
        throw new Error(`STT ì„œë²„ ì˜¤ë¥˜: ${response.status}`);
      }
      
      const data = await response.json();
      const recognizedText = data.recognized_text;
      
      console.log('âœ… ë°±ì—”ë“œ STT ê²°ê³¼:', recognizedText);
      
      if (recognizedText && recognizedText.trim()) {
        hideOverlay();
        processVoiceQuery(recognizedText.trim());
      } else {
        throw new Error('ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }
      
    } catch (error) {
      console.error('âŒ ë°±ì—”ë“œ STT ì˜¤ë¥˜:', error);
      hideOverlay();
      resetButton();
      displayResponse('STT ì˜¤ë¥˜', error.message, 'ì˜¤ë¥˜');
    }
  };

  // ì™„ì „í•œ ìŒì„± ëŒ€í™” (STT + LLM + TTS)
  const processVoiceChatComplete = async (audioBlob) => {
    setIsProcessing(true);
    updateStatus('processing', 'ğŸ¯', 'ìŒì„± ëŒ€í™” ì²˜ë¦¬ ì¤‘...', 'STT â†’ LLM â†’ TTS ì²˜ë¦¬ ì¤‘');
    
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.wav');
      formData.append('voice_name', 'ko-KR-HyunsuMultilingualNeural');
      
      const response = await fetch('http://localhost:8000/chatbot/voice-chat', {
        method: 'POST',
        body: formData
      });
      
      if (!response.ok) {
        throw new Error(`ìŒì„± ëŒ€í™” ì„œë²„ ì˜¤ë¥˜: ${response.status}`);
      }
      
      const data = await response.json();
      console.log('âœ… ì™„ì „í•œ ìŒì„± ëŒ€í™” ê²°ê³¼:', data);
      
      const recognizedText = data.recognized_text;
      const answer = data.answer;
      const source = data.source;
      
      // ì‘ë‹µ í‘œì‹œ
      displayResponse(recognizedText, answer, source);
      
      // ë°±ì—”ë“œì—ì„œ ìƒì„±ëœ ìŒì„± ì¬ìƒ
      if (data.audio_data) {
        playBackendAudio(data.audio_data);
      } else {
        // ë°±ì—”ë“œ TTS ì‹¤íŒ¨ ì‹œ ë¸Œë¼ìš°ì € TTSë¡œ ëŒ€ì²´
        speakText(answer);
      }
      
    } catch (error) {
      console.error('âŒ ì™„ì „í•œ ìŒì„± ëŒ€í™” ì˜¤ë¥˜:', error);
      hideOverlay();
      resetButton();
      displayResponse('ìŒì„± ëŒ€í™” ì˜¤ë¥˜', error.message, 'ì˜¤ë¥˜');
    } finally {
      setIsProcessing(false);
    }
  };

  // ìŒì„± ìƒí˜¸ì‘ìš© ì‹œì‘/ì¤‘ì§€
  const startVoiceInteraction = () => {
    // ìŒì„± ì¬ìƒ ì¤‘ì´ë©´ ì¤‘ì§€
    if (isSpeaking) {
      stopSpeaking();
      return;
    }

    // ë…¹ìŒ ì¤‘ì´ë©´ ì¤‘ì§€
    if (isRecording) {
      stopRecording();
      return;
    }

    // ì²˜ë¦¬ ì¤‘ì´ë©´ ì·¨ì†Œ
    if (isProcessing) {
      cancelVoiceInteraction();
      return;
    }

    // ìƒˆë¡œìš´ ìŒì„± ì¸ì‹ ì‹œì‘
    showVoiceOverlay();
    setIsRecording(true);

    if (useBackendSTT ) {
      // ë°±ì—”ë“œ STT ì‚¬ìš©: ì˜¤ë””ì˜¤ ë…¹ìŒ

      startBackendRecording();
  } else {
    // ë¸Œë¼ìš°ì € STT ì‚¬ìš©: Web Speech API (ê¶Œí•œ ìš”ì²­ ì—†ìŒ)
    if (!recognitionRef.current) {
      hideOverlay();
      resetButton();
      return;
    }
      

      try {
        recognitionRef.current.start();
      } catch (error) {
        console.error('ìŒì„± ì¸ì‹ ì‹œì‘ ì˜¤ë¥˜:', error);
        hideOverlay();
        resetButton();
      }
    }
  };


const startBackendRecording = async () => {
  try {
    // ğŸ”§ ì—¬ê¸°ì„œ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ (ì‚¬ìš©í•  ë•Œë§Œ)
    const stream = await navigator.mediaDevices.getUserMedia({ 
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    });
    
    // ğŸ”§ ë§¤ë²ˆ ìƒˆë¡œìš´ MediaRecorder ìƒì„±
    const recorder = new MediaRecorder(stream, {
      mimeType: MediaRecorder.isTypeSupported('audio/wav') ? 'audio/wav' : 'audio/webm'
    });
    
    audioChunksRef.current = [];
    
    recorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunksRef.current.push(event.data);
      }
    };
    
    recorder.onstop = () => {
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
      setRecordedAudio(audioBlob);
      audioChunksRef.current = [];
      
      // ğŸ”§ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ (ê¶Œí•œ í•´ì œ)
      stream.getTracks().forEach(track => track.stop());
      
      // ë°±ì—”ë“œ STT ì²˜ë¦¬
      processBackendSTT(audioBlob);
    };
    
    // ğŸ”§ í˜„ì¬ MediaRecorder ì°¸ì¡° ì €ì¥
    setMediaRecorder(recorder);
    
    recorder.start();
    updateStatus('recording', 'ğŸ”´', 'ìŒì„± ë…¹ìŒ ì¤‘...', 'ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤');
    
  } catch (error) {
    console.error('ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì‹¤íŒ¨:', error);
    hideOverlay();
    resetButton();
    
    // ğŸ”§ êµ¬ì²´ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€
    if (error.name === 'NotAllowedError') {
      alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì €ì—ì„œ ë§ˆì´í¬ ì ‘ê·¼ì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
    } else if (error.name === 'NotFoundError') {
      alert('ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.');
    } else {
      alert('ë§ˆì´í¬ ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  }
};


  // ìŒì„± ì¬ìƒ ì¤‘ì§€
  const stopSpeaking = () => {
    console.log('ğŸ”‡ ìŒì„± ì¬ìƒ ì¤‘ì§€ ìš”ì²­');
    
    // ë¸Œë¼ìš°ì € TTS ì¤‘ì§€
    if (speechSynthesisRef.current.speaking) {
      console.log('ğŸ”‡ ë¸Œë¼ìš°ì € TTS ì¤‘ì§€');
      speechSynthesisRef.current.cancel();
    }
    
    // ë°±ì—”ë“œ ì˜¤ë””ì˜¤ ì¤‘ì§€
    if (window.currentBackendAudio) {
      console.log('ğŸ”‡ ë°±ì—”ë“œ ì˜¤ë””ì˜¤ ì¤‘ì§€');
      window.currentBackendAudio.pause();
      window.currentBackendAudio.currentTime = 0;
      window.currentBackendAudio = null;
    }
    
    setIsSpeaking(false);
    hideOverlay();
    resetButton();
  };
// ğŸ”§ ìˆ˜ì • 5: stopRecording í•¨ìˆ˜ ìˆ˜ì •
const stopRecording = () => {
  console.log('â¹ï¸ ë…¹ìŒ ì¤‘ì§€');
  
  if (useBackendSTT && mediaRecorder && mediaRecorder.state === 'recording') {
    mediaRecorder.stop();
    // ğŸ”§ MediaRecorder ì°¸ì¡° ì •ë¦¬
    setMediaRecorder(null);
  }
  
  if (recognitionRef.current) {
    recognitionRef.current.stop();
  }
  
  setIsRecording(false);
  hideOverlay();
  resetButton();
};

  // ìŒì„± ì¿¼ë¦¬ ì²˜ë¦¬ (ë°±ì—”ë“œ TTS ì‚¬ìš© ì˜µì…˜)
  const processVoiceQuery = async (query) => {
    setIsProcessing(true);
    updateStatus('processing', 'âš™ï¸', 'AIê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤...', 'ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”');
    
    try {
      console.log('ğŸ”„ API ì„œë²„ì— ì§ˆë¬¸ ì „ì†¡:', query);
      
      // ë°±ì—”ë“œ TTS ì‚¬ìš© ì—¬ë¶€ (trueë©´ ì„œë²„ TTS, falseë©´ ë¸Œë¼ìš°ì € TTS)
      const useBackendTTS = false;
      
      if (useBackendTTS) {
        // ë°±ì—”ë“œ TTS ì‚¬ìš©
        const formData = new FormData();
        formData.append('query', query);
        formData.append('voice_name', 'ko-KR-HyunsuMultilingualNeural');

        const response = await fetch('http://localhost:8000/chatbot/ask-with-voice', {
          method: 'POST',
          body: formData
        });

        if (!response.ok) {
          throw new Error(`ì„œë²„ ì˜¤ë¥˜: ${response.status}`);
        }

        const data = await response.json();
        console.log('âœ… API ì‘ë‹µ ìˆ˜ì‹  (TTS í¬í•¨):', data);

        const answer = data.answer || 'ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
        const source = data.source || 'ì•Œ ìˆ˜ ì—†ìŒ';

        // ì‘ë‹µ í‘œì‹œ
        displayResponse(query, answer, source);
        
        // ë°±ì—”ë“œì—ì„œ ìƒì„±ëœ ìŒì„± ì¬ìƒ
        if (data.audio_data) {
          playBackendAudio(data.audio_data);
        } else {
          // ë°±ì—”ë“œ TTS ì‹¤íŒ¨ ì‹œ ë¸Œë¼ìš°ì € TTSë¡œ ëŒ€ì²´
          speakText(answer);
        }
      } else {
        // ê¸°ì¡´ ë°©ì‹: ë¸Œë¼ìš°ì € TTS ì‚¬ìš©
        const formData = new FormData();
        formData.append('query', query);

        const response = await fetch('http://localhost:8000/chatbot/ask', {
          method: 'POST',
          body: formData
        });

        if (!response.ok) {
          throw new Error(`ì„œë²„ ì˜¤ë¥˜: ${response.status}`);
        }

        const data = await response.json();
        console.log('âœ… API ì‘ë‹µ ìˆ˜ì‹ :', data);

        const answer = data.answer || 'ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
        const source = data.source || 'ì•Œ ìˆ˜ ì—†ìŒ';

        // ì‘ë‹µ í‘œì‹œ
        displayResponse(query, answer, source);
        
        // ë¸Œë¼ìš°ì € TTSë¡œ ìŒì„± ì¶œë ¥
        speakText(answer);
      }

    } catch (error) {
      console.error('âŒ API í˜¸ì¶œ ì˜¤ë¥˜:', error);
      
      let errorMessage = 'ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      if (error.message.includes('fetch')) {
        errorMessage = 'ë°±ì—”ë“œ ì„œë²„(localhost:8000)ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nâ€¢ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”\nâ€¢ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”';
      }
      
      displayResponse(query, errorMessage, 'ì—°ê²° ì˜¤ë¥˜');
    } finally {
      setIsProcessing(false);
      hideOverlay();
      resetButton();
    }
  };

  // ë°±ì—”ë“œì—ì„œ ìƒì„±ëœ ìŒì„± ì¬ìƒ
  const playBackendAudio = (audioBase64) => {
    try {
      updateStatus('speaking', 'ğŸ”Š', 'AIê°€ ë‹µë³€í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'ë°±ì—”ë“œ TTSë¡œ ìŒì„± ì¶œë ¥ ì¤‘');
      setIsSpeaking(true);
      
      // Base64ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
      const audioBytes = atob(audioBase64);
      const audioArray = new Uint8Array(audioBytes.length);
      for (let i = 0; i < audioBytes.length; i++) {
        audioArray[i] = audioBytes.charCodeAt(i);
      }
      
      const audioBlob = new Blob([audioArray], { type: 'audio/wav' });
      const audioUrl = URL.createObjectURL(audioBlob);
      
      const audio = new Audio(audioUrl);
      
      audio.onloadstart = () => {
        console.log('ğŸ”Š ë°±ì—”ë“œ TTS ë¡œë”© ì‹œì‘');
      };
      
      audio.onplay = () => {
        console.log('ğŸ”Š ë°±ì—”ë“œ TTS ì¬ìƒ ì‹œì‘');
        setIsSpeaking(true);
        updateStatus('speaking', 'ğŸ”‡', 'AIê°€ ë‹µë³€ ì¤‘ì…ë‹ˆë‹¤', 'ë²„íŠ¼ì„ ëˆŒëŸ¬ ì¤‘ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤');
      };
      
      audio.onended = () => {
        console.log('âœ… ë°±ì—”ë“œ TTS ì¬ìƒ ì™„ë£Œ');
        setIsSpeaking(false);
        hideOverlay();
        resetButton();
        URL.revokeObjectURL(audioUrl); // ë©”ëª¨ë¦¬ ì •ë¦¬
      };
      
      audio.onerror = (error) => {
        console.error('âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', error);
        setIsSpeaking(false);
        hideOverlay();
        resetButton();
        URL.revokeObjectURL(audioUrl);
      };

      // ë°±ì—”ë“œ ì˜¤ë””ì˜¤ ì¤‘ì§€ë¥¼ ìœ„í•´ ì°¸ì¡° ì €ì¥
      window.currentBackendAudio = audio;
      
      audio.play();
      
    } catch (error) {
      console.error('ë°±ì—”ë“œ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', error);
      setIsSpeaking(false);
      hideOverlay();
      resetButton();
    }
  };

  // í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (ë¸Œë¼ìš°ì € TTS)
  const speakText = (text) => {
    updateStatus('speaking', 'ğŸ”Š', 'AIê°€ ë‹µë³€í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'ìŒì„±ìœ¼ë¡œ ë“£ê³  ê³„ì„¸ìš”');
    setIsSpeaking(true);
    
    // ê¸°ì¡´ ìŒì„± ì¤‘ì§€
    speechSynthesisRef.current.cancel();

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ko-KR';
    utterance.rate = 1.0;
    utterance.pitch = 1.0;
    utterance.volume = 0.8;

    // í•œêµ­ì–´ ìŒì„± ì„ íƒ
    const voices = speechSynthesisRef.current.getVoices();
    const koreanVoice = voices.find(voice => 
      voice.lang.includes('ko') || voice.name.includes('Korean')
    );
    if (koreanVoice) {
      utterance.voice = koreanVoice;
    }

    utterance.onstart = () => {
      console.log('ğŸ”Š ë¸Œë¼ìš°ì € TTS ì‹œì‘');
      setIsSpeaking(true);
      updateStatus('speaking', 'ğŸ”‡', 'AIê°€ ë‹µë³€ ì¤‘ì…ë‹ˆë‹¤', 'ë²„íŠ¼ì„ ëˆŒëŸ¬ ì¤‘ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤');
    };

    utterance.onend = () => {
      console.log('âœ… ë¸Œë¼ìš°ì € TTS ì™„ë£Œ');
      setIsSpeaking(false);
      hideOverlay();
      resetButton();
    };

    utterance.onerror = (event) => {
      console.error('âŒ TTS ì˜¤ë¥˜:', event);
      setIsSpeaking(false);
      hideOverlay();
      resetButton();
    };

    speechSynthesisRef.current.speak(utterance);
  };

  // ìƒíƒœ ì—…ë°ì´íŠ¸
  const updateStatus = (type, icon, text, subText) => {
    setStatusIcon(icon);
    setStatusText(text);
    setShowOverlay(true);
  };

  // ì˜¤ë²„ë ˆì´ í‘œì‹œ
  const showVoiceOverlay = () => {
    setShowOverlay(true);
  };

  // ì˜¤ë²„ë ˆì´ ìˆ¨ê¸°ê¸°
  const hideOverlay = () => {
    setShowOverlay(false);
  };

  // ë²„íŠ¼ ë¦¬ì…‹
  const resetButton = () => {
    setIsRecording(false);
    setIsProcessing(false);
    setIsSpeaking(false);
  };

  // ì‘ë‹µ í‘œì‹œ
  const displayResponse = (question, answer, source) => {
    setResponseData({ question, answer, source });
    setShowResponse(true);
  };

  // ìŒì„± ìƒí˜¸ì‘ìš© ì·¨ì†Œ
  const cancelVoiceInteraction = () => {
    console.log('â¹ï¸ ìŒì„± ìƒí˜¸ì‘ìš© ì·¨ì†Œ');
    
    // ë…¹ìŒ ì¤‘ì§€
    if (useBackendSTT && mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
    }
    if (recognitionRef.current) {
      recognitionRef.current.abort();
    }
    
    // ìŒì„± ì¬ìƒ ì¤‘ì§€
    stopSpeaking();
    
    hideOverlay();
    resetButton();
  };

  // ì‘ë‹µ ì°½ ë‹«ê¸°
  const closeResponse = () => {
    setShowResponse(false);
  };

  // ë²„íŠ¼ í´ë˜ìŠ¤ ê²°ì •
  const getButtonClass = () => {
    if (isRecording) return 'voice-floating-btn recording';
    if (isProcessing) return 'voice-floating-btn processing';
    if (isSpeaking) return 'voice-floating-btn speaking';
    return 'voice-floating-btn';
  };

  // ë²„íŠ¼ ì•„ì´ì½˜ ê²°ì •
  const getButtonIcon = () => {
    if (isRecording) return 'â¹ï¸';  // ë…¹ìŒ ì¤‘ â†’ ì¤‘ì§€ ì•„ì´ì½˜
    if (isProcessing) return 'â¹ï¸'; // ì²˜ë¦¬ ì¤‘ â†’ ì¤‘ì§€ ì•„ì´ì½˜
    if (isSpeaking) return 'ğŸ”‡';   // ìŒì„± ì¬ìƒ ì¤‘ â†’ ìŒì†Œê±° ì•„ì´ì½˜
    return 'ğŸ¤';                  // ê¸°ë³¸ â†’ ë§ˆì´í¬ ì•„ì´ì½˜
  };

  // ë²„íŠ¼ íƒ€ì´í‹€ ê²°ì •
  const getButtonTitle = () => {
    if (isRecording) return 'ë…¹ìŒ ì¤‘ì§€';
    if (isProcessing) return 'ì²˜ë¦¬ ì·¨ì†Œ';
    if (isSpeaking) return 'ìŒì„± ì¤‘ì§€';
    return 'ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸í•˜ê¸°';
  };

  // ì†ŒìŠ¤ í‘œì‹œ í…ìŠ¤íŠ¸
  const getSourceDisplay = (source) => {
    const sourceMap = {
      'RAG': 'ğŸ“š ì „ë¬¸ìë£Œ',
      'í•˜ë“œì½”ë”©ëœ RAG': 'ğŸ“‹ ê¸°ë³¸ì •ë³´',
      'ìˆ˜ë™ RAG': 'ğŸ” ê²€ìƒ‰ìë£Œ',
      'ì¼ë°˜ LLM': 'ğŸ§  AIì§€ì‹',
      'ì—°ê²° ì˜¤ë¥˜': 'âš ï¸ ì—°ê²°ì˜¤ë¥˜',
      'ì˜¤ë¥˜': 'âŒ ì˜¤ë¥˜'
    };
    return sourceMap[source] || 'ğŸ¤– AI';
  };

  return (
    <div style={{ position: 'relative' }}>
      {/* ìŒì„± ìƒíƒœ ì˜¤ë²„ë ˆì´ */}
      {showOverlay && (
        <div style={{
          position: 'fixed',
          top: 0,
          left: 0,
          width: '100vw',
          height: '100vh',
          background: 'rgba(0, 0, 0, 0.7)',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          zIndex: 9999,
          animation: 'fadeIn 0.3s ease'
        }}>
          <div style={{
            background: 'white',
            padding: '40px',
            borderRadius: '20px',
            textAlign: 'center',
            boxShadow: '0 20px 60px rgba(0, 0, 0, 0.3)',
            maxWidth: '400px',
            width: '90%',
            transform: 'scale(1)',
            animation: 'scaleIn 0.3s ease'
          }}>
            <span style={{ fontSize: '60px', marginBottom: '20px', display: 'block' }}>
              {statusIcon}
            </span>
            <div style={{ fontSize: '18px', fontWeight: '600', color: '#333', marginBottom: '10px' }}>
              {statusText}
            </div>
            <div style={{ fontSize: '14px', color: '#666', marginBottom: '30px' }}>
              {isSpeaking ? 
                'ğŸ”‡ ìŒì„± ì¬ìƒ ì¤‘ì…ë‹ˆë‹¤. ë²„íŠ¼ì„ ëˆŒëŸ¬ ì¤‘ì§€í•˜ì„¸ìš”.' :
                useBackendSTT ? 
                (isRecording ? 'ë…¹ìŒ ì¤‘... ë§ì”€ì´ ëë‚˜ë©´ ì¤‘ì§€ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”' : 'ë§ˆì´í¬ì— ëŒ€ê³  ë§ì”€í•´ì£¼ì„¸ìš”') :
                'ë§ˆì´í¬ì— ëŒ€ê³  ë§ì”€í•´ì£¼ì„¸ìš”'
              }
            </div>
            <div style={{ marginBottom: '20px' }}>
              {isRecording && useBackendSTT && (
                <button
                  onClick={stopRecording}
                  style={{
                    background: '#28a745',
                    color: 'white',
                    border: 'none',
                    padding: '10px 20px',
                    borderRadius: '6px',
                    cursor: 'pointer',
                    fontSize: '14px',
                    marginRight: '10px'
                  }}
                >
                  ë…¹ìŒ ì™„ë£Œ
                </button>
              )}
              {(isRecording || isProcessing || isSpeaking) && (
                <button
                  onClick={cancelVoiceInteraction}
                  style={{
                    background: '#dc3545',
                    color: 'white',
                    border: 'none',
                    padding: '10px 20px',
                    borderRadius: '6px',
                    cursor: 'pointer',
                    fontSize: '14px'
                  }}
                >
                  {isSpeaking ? 'ğŸ”‡ ìŒì„± ì¤‘ì§€' : 'â¹ï¸ ì·¨ì†Œ'}
                </button>
              )}
            </div>
            <div style={{ fontSize: '12px', color: '#888', marginBottom: '20px' }}>
              STT ë°©ì‹: {useBackendSTT ? 'ë°±ì—”ë“œ (Azure Speech)' : 'ë¸Œë¼ìš°ì € (Web Speech API)'}
            </div>
            <button
              onClick={cancelVoiceInteraction}
              style={{
                background: '#ff4757',
                color: 'white',
                border: 'none',
                padding: '12px 24px',
                borderRadius: '8px',
                cursor: 'pointer',
                fontSize: '16px',
                fontWeight: '600'
              }}
            >
              ë‹«ê¸°
            </button>
          </div>
        </div>
      )}

      {/* ì‘ë‹µ íŒì—… */}
      {showResponse && (
        <div style={{
          position: 'fixed',
          bottom: '120px',
          right: '30px',
          width: '350px',
          maxWidth: 'calc(100vw - 60px)',
          background: 'white',
          borderRadius: '16px',
          boxShadow: '0 10px 40px rgba(0, 0, 0, 0.15)',
          padding: '20px',
          zIndex: 9998,
          animation: 'slideUp 0.3s ease'
        }}>
          <div style={{ marginBottom: '20px' }}>
            <label style={{ display: 'flex', alignItems: 'center', gap: '8px', cursor: 'pointer' }}>
              <input
                type="checkbox"
                checked={useBackendSTT}
                onChange={(e) => setUseBackendSTT(e.target.checked)}
              />
              <span style={{ fontSize: '14px' }}>ë°±ì—”ë“œ STT ì‚¬ìš© (Azure Speech Service)</span>
            </label>
          </div>
          
          <div style={{
            display: 'flex',
            alignItems: 'center',
            justifyContent: 'space-between',
            marginBottom: '15px',
            paddingBottom: '10px',
            borderBottom: '1px solid #eee'
          }}>
            <div style={{
              fontWeight: '600',
              color: '#333',
              display: 'flex',
              alignItems: 'center',
              gap: '8px'
            }}>
              <span>ğŸ¤–</span>
              <span>AI ì–´ì‹œìŠ¤í„´íŠ¸</span>
            </div>
            <button
              onClick={closeResponse}
              style={{
                background: 'none',
                border: 'none',
                fontSize: '18px',
                cursor: 'pointer',
                color: '#999',
                padding: 0,
                width: '24px',
                height: '24px',
                display: 'flex',
                alignItems: 'center',
                justifyContent: 'center'
              }}
            >
              âœ•
            </button>
          </div>
          
          {responseData.question && (
            <div style={{
              background: '#f0f8ff',
              padding: '10px',
              borderRadius: '8px',
              marginBottom: '10px',
              fontSize: '14px',
              color: '#555'
            }}>
              <strong>ì§ˆë¬¸:</strong> {responseData.question}
            </div>
          )}
          
          <div style={{
            color: '#555',
            lineHeight: '1.5',
            fontSize: '14px',
            whiteSpace: 'pre-wrap',
            maxHeight: '300px',
            overflowY: 'auto'
          }}>
            {responseData.answer}
          </div>
          
          {responseData.source && (
            <div style={{
              fontSize: '12px',
              color: '#888',
              marginTop: '10px',
              paddingTop: '10px',
              borderTop: '1px solid #eee'
            }}>
              ì¶œì²˜: {getSourceDisplay(responseData.source)}
            </div>
          )}
        </div>
      )}

      {/* í”Œë¡œíŒ… ìŒì„± ë²„íŠ¼ */}
      <button
        className={getButtonClass()}
        onClick={startVoiceInteraction}
        title={getButtonTitle()}
        style={{
          position: 'fixed',
          bottom: '30px',
          right: '30px',
          width: '70px',
          height: '70px',
          background: isRecording 
            ? 'linear-gradient(135deg, #ff4757 0%, #c44569 100%)'
            : isProcessing 
            ? 'linear-gradient(135deg, #ffa502 0%, #ff6348 100%)'
            : isSpeaking
            ? 'linear-gradient(135deg, #2ed573 0%, #1e90ff 100%)'
            : 'linear-gradient(135deg, #ff6b6b 0%, #ee5a52 100%)',
          border: 'none',
          borderRadius: '50%',
          cursor: 'pointer',
          boxShadow: '0 8px 30px rgba(255, 107, 107, 0.4)',
          transition: 'all 0.3s cubic-bezier(0.4, 0, 0.2, 1)',
          zIndex: 10000,
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          color: 'white',
          fontSize: '28px',
          outline: 'none',
          animation: isRecording 
            ? 'pulse 1.5s infinite'
            : isProcessing 
            ? 'spin 1s linear infinite'
            : isSpeaking
            ? 'wave 1s ease-in-out infinite alternate'
            : 'none'
        }}
      >
        {getButtonIcon()}
      </button>

      {/* ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼ */}
      <style>{`
        @keyframes pulse {
          0% { transform: scale(1); }
          50% { transform: scale(1.1); box-shadow: 0 12px 40px rgba(255, 71, 87, 0.6); }
          100% { transform: scale(1); }
        }

        @keyframes spin {
          from { transform: rotate(0deg); }
          to { transform: rotate(360deg); }
        }

        @keyframes wave {
          0% { transform: scale(1); }
          100% { transform: scale(1.08); }
        }

        @keyframes fadeIn {
          from { opacity: 0; }
          to { opacity: 1; }
        }

        @keyframes scaleIn {
          from { transform: scale(0.9); }
          to { transform: scale(1); }
        }

        @keyframes slideUp {
          from { transform: translateY(20px); opacity: 0; }
          to { transform: translateY(0); opacity: 1; }
        }

        .voice-floating-btn:hover {
          transform: translateY(-3px) scale(1.05) !important;
          box-shadow: 0 12px 40px rgba(255, 107, 107, 0.5) !important;
        }
      `}</style>
    </div>
  );
};

export default VoiceAssistantWidget;